# Dissolve: Technical Steering Meeting
### Fri 16/04/2021 13:30 - 14:30
### CR11 - RL, R3 (20, VC)

### Attending

- Tristan Youngs (TY)
- Daniel Nixon (DN)
- Adam Washington (AW)
- Stephen Smith (SS)
- Anders Markvaardsen (AM)

#### Apologies

- Lamar Moore (LM)

### Agenda

1. Sprint Review, weeks 13-15
2. User Interface Upgrades
3. Parallelism
4. Benchmarking
5. AOB


## 1. Sprint Review

- TY noted that the past sprint was three weeks long, since it covered the Easter period, but that a significant number of PRs of good size had been approved and merged.
- TY noted that the outstanding Accumulation PR (#629) was ready for review and that, once merged, this capability would bring Dissolve closer in line to the operation of EPSR. THis feature is to be tested by CG and HBK in the forthcoming weeks.
- TY enquired about the status of the XML importer (#583) to which AW stated that all outstanding issues were fixed, and that it was ready for merge. TY subsequently approved the PR.
- TY noted that the parallelism (and benchmarking) work performed by SS is not captured by this sprint.
- TY mentioned that the UFF4MOF work (#561) was undergoing final modifications by CG, and would be ready for review next week.
- Unfinished PRs covering Bragg calculation, the UFF4MOF work, and Model/View patternisations were moved to the following sprint.

## 2. User Interface Upgrades

- AW stated that he had been busy investigating the use of QML in the GUI, but that those investigations had highlighted some significant hurdles.
- AW mentioned that, in particular, table generation within QML is half-baked and would require significant additional work to bring a QML-based incarnation of the current GUI capability to fruition.
- AW described that one problem in particular was table headers, which requires considerable effort on the part of the developer to achieve quite standard things such as generating the headers in the first place, and resizing them to their underlying contents.
- AM mentioned an ESS software project, https://easydiffraction.org/, for which he was aware that they had use QML for the GUI.
- TY asked if this was a Python/PyQml project, to which AM replied yes.
- TY was concerned that, from the website, the GUI looks relatively simplistic compared to Dissolve's, and if this project had trouble using QML then this was cause for concern.
- AW investigated the GitHub repo for the project, and quickly found that the developers had been required to implement most of the workarounds he had already mentioned.
- AW noted that most of the functionality we required (especially automated testing) can be achieved without QML with some additional work.
- It was agreed that the use of QML within Dissolve should be put aside for now, since there is not enough resource in the team to be able to effectively take on the required additional coding.

## 3. Parallelism

- TY described some tests he had been running of #611 on SCARF, which showed that (for water10k.txt on 8 cores) the PSTL version was approximately three times faster in the cell-based G(r) calculation than the MPI version.
- TY was keen to stress that this is an exceptional result and needs further validation - e.g. correct config of SLURM, consistency of calculated g(r) with "correct" values etc. - but this was a very encouraging result.
- TY questioned the planned direction of the parallel work - in particular whether we would develop a purely PSTL version alongside the existing MPI version.
- SS questioned whether the complete removal of MPI was the goal, and mentioned that he had previously tackled engineering problems using MPI to distribute tasks across nodes, and then use multithreading locally on nodes.
- AW agreed with this last comment, and suggested that careful refactoring and curation of a small MPI presence within the code to achieve this would be a good approach.
- TY mentioned that the original design of the code was to allow any process to do any task independently of any other, hence the need for broadcast / sharing of any data back between all processes at some point. He agreed that, provided MPI/multithreading was employed as a strategy on a local algorithm level, this would be a good route to follow.
- It was agreed by the team that a combination of MPI/multithreading would be used as the parallelism model going forward.
- TY stated that there were four obvious core areas to tackle - radial distribution function, energy, and force calculation, and Monte Carlo evolution. He mentioned that the first three are more-or-less trivially parallelisable on a higher level, while the Monte Carlo approach requires some kind of domain decomposition which is already alluded to the MPI versions of those routines. TY will discuss this with SS at a later date.

ACTION: TY to validate g(r) calculated by PSTL algorithm.

## 4. Benchmarking

- SS summarised progress on the benchmarking PR (#624) stating that modifications from past review comments were complete, and that a handful of new benchmarks had been added.
- SS asked where this particular PR would go next, particularly in respect of integration with GitHub Actions.
- For the benefit of others in the meeting, TY explained the potential integration of running these google_benchmark tests within an existing GitHub Action (https://github.com/marketplace/actions/continuous-benchmark) which will automatically run defined benchmark calculations and store / graph the results in the repositories GitHub Pages instance, providing performance metrics on a per-commit basis.
- DN wanted to know how these google_benchmarks were being applied, as they are typically used to measure performance of critical, small routines within a code, and that something more "user level" (i.e. simulations of relevance to them) would be more useful.
- TY explained that Dissolve currently has a crude version of the latter, and that the google_benchmarks SS is implementing covers the former.
- TY asked how important benchmarks that cover the "middle ground" are, to which DN replied that he believed they are not really necessary, as performance degradations of critical routines should be evident in the higher-level benchmark tests.
- AM asked whether Dissolve currently has "performance" tests in its benchmark suite, citing other projects that perform such tests on a weekly basis in order to monitor performance degradation.
- TY recalled at this point that SS had already implemented one such benchmark (on the radial distribution function routines) within a google_benchmark in #624, and that leveraging the GitHub Action previously mentioned would allow this to be fully automated.
- DN suggested an alternative to using GitHub Actions - SCD Anvil - raising a concern over the power of the CI machine pool if we were to run intensive benchmarks. However, he also highlighted that this service may not be a reliable / long-lived resource.
- It was agreed that this was a useful CI tool to have.

ACTION: TY and AW to re-review #624.
ACTION: SS to construct preliminary GitHub Action following merge of #624.

## 5. AOB

None raised.
